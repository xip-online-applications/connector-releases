{
  "version": 3,
  "sources": ["../../../../../../../libs/kafka-base-service/src/lib/rdkafka-bulk-listener.service.ts"],
  "sourcesContent": ["import {\n  BaseConnectorConfig,\n  isTopicRegex,\n  XodBaseMessageType,\n} from '@xip-online-data/types';\nimport { EachBatchPayload, KafkaMessage } from 'kafkajs';\nimport { Logger } from '@transai/logger';\nimport { AbstractRdKafkaService } from './abstract-rdkafka-service';\n\nexport class RdKafkaBulkListenerService extends AbstractRdKafkaService {\n  public constructor(\n    baseYamlConfig: BaseConnectorConfig,\n    private readonly callbackFunction: (\n      messages: Array<XodBaseMessageType>,\n    ) => Promise<void>,\n    private readonly bulkApplicable: (\n      messages: Array<XodBaseMessageType>,\n    ) => boolean = () => true,\n  ) {\n    super(baseYamlConfig);\n  }\n\n  public init = async (): Promise<void> => {\n    const regexTopics =\n      this.baseYamlConfig.kafka.consumerTopics?.filter((topic) =>\n        isTopicRegex(topic),\n      ) ?? [];\n    const regularTopics: Array<string> =\n      (this.baseYamlConfig.kafka.consumerTopics?.filter(\n        (topic) => !isTopicRegex(topic),\n      ) as Array<string>) ?? [];\n\n    await Promise.all([\n      ...regexTopics.map(async (topic) => {\n        await this.consumer.subscribe({\n          topic: new RegExp(topic.pattern, topic.flags),\n        });\n      }),\n      ...regularTopics.map(async (topic) => {\n        const t =\n          topic.indexOf(this.baseYamlConfig.tenantIdentifier) !== 0\n            ? `${this.baseYamlConfig.tenantIdentifier}_${topic}`\n            : topic;\n        await this.consumer.subscribe({ topic: t });\n      }),\n    ]);\n\n    if (this.baseYamlConfig.kafka.autoCommitThreshold) {\n      Logger.getInstance().error(\n        'autoCommitThreshold is not supported in bulk listener. Please use autoCommitInterval instead',\n      );\n    }\n\n    await this.consumer.run({\n      partitionsConsumedConcurrently:\n        this.baseYamlConfig.kafka.partitionsConsumedConcurrently ?? 1,\n      eachBatchAutoResolve: true,\n      eachBatch: this.consumeBatch,\n    });\n  };\n\n  private consumeBatch = async ({\n    batch,\n    resolveOffset,\n    heartbeat,\n    pause,\n    commitOffsetsIfNecessary,\n    uncommittedOffsets,\n    isRunning,\n    isStale,\n  }: EachBatchPayload) => {\n    const messages = batch.messages.map((message) =>\n      JSON.parse(message.value.toString()),\n    );\n    Logger.getInstance().debug(\n      'Received batch of messages',\n      messages.length,\n      batch.topic,\n    );\n\n    if (this.bulkApplicable(messages)) {\n      try {\n        await this.callbackFunction(messages);\n        const { offset } = batch.messages[batch.messages.length - 1];\n        resolveOffset(offset);\n      } catch (error) {\n        Logger.getInstance().error(\n          'Error in callback function. Continue as single batch',\n          error,\n        );\n        await this.consumeBatchAsSingle(batch.messages, resolveOffset);\n      }\n    } else {\n      Logger.getInstance().debug(\n        'Batch processing not applicable. Continue as single batch',\n      );\n      await this.consumeBatchAsSingle(batch.messages, resolveOffset);\n    }\n  };\n\n  private consumeBatchAsSingle = async (\n    messages: Array<KafkaMessage>,\n    resolveOffset: (offset: string) => void,\n  ) => {\n    // eslint-disable-next-line no-restricted-syntax\n    for (const message of messages) {\n      try {\n        const parsedMessage = JSON.parse(message.value.toString());\n        // eslint-disable-next-line no-await-in-loop\n        await this.callbackFunction([parsedMessage]);\n        resolveOffset(message.offset);\n      } catch (error) {\n        Logger.getInstance().error('Error in callback function', error);\n        resolveOffset(message.offset);\n      }\n    }\n  };\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAIO;AAEP,oBAAuB;AACvB,sCAAuC;AAEhC,MAAM,mCAAmC,uDAAuB;AAAA,EAC9D,YACL,gBACiB,kBAGA,iBAEF,MAAM,MACrB;AACA,UAAM,cAAc;AAPH;AAGA;AAOnB,SAAO,OAAO,YAA2B;AACvC,YAAM,cACJ,KAAK,eAAe,MAAM,gBAAgB;AAAA,QAAO,CAAC,cAChD,2BAAa,KAAK;AAAA,MACpB,KAAK,CAAC;AACR,YAAM,gBACH,KAAK,eAAe,MAAM,gBAAgB;AAAA,QACzC,CAAC,UAAU,KAAC,2BAAa,KAAK;AAAA,MAChC,KAAuB,CAAC;AAE1B,YAAM,QAAQ,IAAI;AAAA,QAChB,GAAG,YAAY,IAAI,OAAO,UAAU;AAClC,gBAAM,KAAK,SAAS,UAAU;AAAA,YAC5B,OAAO,IAAI,OAAO,MAAM,SAAS,MAAM,KAAK;AAAA,UAC9C,CAAC;AAAA,QACH,CAAC;AAAA,QACD,GAAG,cAAc,IAAI,OAAO,UAAU;AACpC,gBAAM,IACJ,MAAM,QAAQ,KAAK,eAAe,gBAAgB,MAAM,IACpD,GAAG,KAAK,eAAe,gBAAgB,IAAI,KAAK,KAChD;AACN,gBAAM,KAAK,SAAS,UAAU,EAAE,OAAO,EAAE,CAAC;AAAA,QAC5C,CAAC;AAAA,MACH,CAAC;AAED,UAAI,KAAK,eAAe,MAAM,qBAAqB;AACjD,6BAAO,YAAY,EAAE;AAAA,UACnB;AAAA,QACF;AAAA,MACF;AAEA,YAAM,KAAK,SAAS,IAAI;AAAA,QACtB,gCACE,KAAK,eAAe,MAAM,kCAAkC;AAAA,QAC9D,sBAAsB;AAAA,QACtB,WAAW,KAAK;AAAA,MAClB,CAAC;AAAA,IACH;AAEA,SAAQ,eAAe,OAAO;AAAA,MAC5B;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF,MAAwB;AACtB,YAAM,WAAW,MAAM,SAAS;AAAA,QAAI,CAAC,YACnC,KAAK,MAAM,QAAQ,MAAM,SAAS,CAAC;AAAA,MACrC;AACA,2BAAO,YAAY,EAAE;AAAA,QACnB;AAAA,QACA,SAAS;AAAA,QACT,MAAM;AAAA,MACR;AAEA,UAAI,KAAK,eAAe,QAAQ,GAAG;AACjC,YAAI;AACF,gBAAM,KAAK,iBAAiB,QAAQ;AACpC,gBAAM,EAAE,OAAO,IAAI,MAAM,SAAS,MAAM,SAAS,SAAS,CAAC;AAC3D,wBAAc,MAAM;AAAA,QACtB,SAAS,OAAO;AACd,+BAAO,YAAY,EAAE;AAAA,YACnB;AAAA,YACA;AAAA,UACF;AACA,gBAAM,KAAK,qBAAqB,MAAM,UAAU,aAAa;AAAA,QAC/D;AAAA,MACF,OAAO;AACL,6BAAO,YAAY,EAAE;AAAA,UACnB;AAAA,QACF;AACA,cAAM,KAAK,qBAAqB,MAAM,UAAU,aAAa;AAAA,MAC/D;AAAA,IACF;AAEA,SAAQ,uBAAuB,OAC7B,UACA,kBACG;AAEH,iBAAW,WAAW,UAAU;AAC9B,YAAI;AACF,gBAAM,gBAAgB,KAAK,MAAM,QAAQ,MAAM,SAAS,CAAC;AAEzD,gBAAM,KAAK,iBAAiB,CAAC,aAAa,CAAC;AAC3C,wBAAc,QAAQ,MAAM;AAAA,QAC9B,SAAS,OAAO;AACd,+BAAO,YAAY,EAAE,MAAM,8BAA8B,KAAK;AAC9D,wBAAc,QAAQ,MAAM;AAAA,QAC9B;AAAA,MACF;AAAA,IACF;AAAA,EAhGA;AAiGF;",
  "names": []
}
