{
  "version": 3,
  "sources": ["../../../../../../../libs/kafka-base-service/src/lib/rdkafka-bulk-listener.service.ts"],
  "sourcesContent": ["import {\n  BaseConnectorConfig,\n  XodBaseMessageType,\n} from '@xip-online-data/types';\nimport { Logger } from '@transai/logger';\nimport { AbstractRdKafkaService } from './abstract-rdkafka-service';\nimport { KafkaJS } from '@confluentinc/kafka-javascript';\n\nexport class RdKafkaBulkListenerService extends AbstractRdKafkaService {\n  public constructor(\n    baseYamlConfig: BaseConnectorConfig,\n    private readonly callbackFunction: (\n      messages: Array<XodBaseMessageType>,\n    ) => Promise<void>,\n    private readonly bulkApplicable: (\n      messages: Array<XodBaseMessageType>,\n    ) => boolean = () => true,\n  ) {\n    super(baseYamlConfig);\n  }\n\n  public init = async (): Promise<void> => {\n    await this.consumer.connect().catch((e) => {\n      Logger.getInstance().error(\n        `Failed to connect to Kafka consumer: ${e.message}`,\n      );\n      throw new Error(`Failed to connect to Kafka consumer: ${e.message}`);\n    });\n\n    const topics = [\n      ...(await this.getRegexTopics()),\n      ...this.getRegularTopics(),\n    ];\n\n    await Promise.all([\n      ...topics.map(async (t) => {\n        await this.consumer.subscribe({ topic: t });\n      }),\n    ]);\n\n    if (this.baseYamlConfig.kafka.autoCommitThreshold) {\n      Logger.getInstance().error(\n        'autoCommitThreshold is not supported in bulk listener. Please use autoCommitInterval instead',\n      );\n    }\n\n    await this.consumer.run({\n      partitionsConsumedConcurrently:\n        this.baseYamlConfig.kafka.partitionsConsumedConcurrently ?? 1,\n      eachBatchAutoResolve: true,\n      eachBatch: this.consumeBatch,\n    });\n  };\n\n  private consumeBatch = async ({\n    batch,\n    resolveOffset,\n  }: KafkaJS.EachBatchPayload): Promise<void> => {\n    const messages = batch.messages.map((message) =>\n      JSON.parse(message.value?.toString() ?? ''),\n    );\n    Logger.getInstance().debug(\n      'Received batch of messages',\n      messages.length,\n      batch.topic,\n    );\n\n    if (this.bulkApplicable(messages)) {\n      try {\n        await this.callbackFunction(messages);\n        const { offset } = batch.messages[batch.messages.length - 1];\n        resolveOffset(offset);\n      } catch (error) {\n        Logger.getInstance().error(\n          'Error in callback function. Continue as single batch',\n          error,\n        );\n        await this.consumeBatchAsSingle(batch.messages, resolveOffset);\n      }\n    } else {\n      Logger.getInstance().debug(\n        'Batch processing not applicable. Continue as single batch',\n      );\n      await this.consumeBatchAsSingle(batch.messages, resolveOffset);\n    }\n  };\n\n  private consumeBatchAsSingle = async (\n    messages: Array<KafkaJS.KafkaMessage>,\n    resolveOffset: (offset: string) => void,\n  ) => {\n    // eslint-disable-next-line no-restricted-syntax\n    for (const message of messages) {\n      try {\n        const parsedMessage = JSON.parse(message.value?.toString() ?? '{}');\n        // eslint-disable-next-line no-await-in-loop\n        await this.callbackFunction([parsedMessage]);\n        resolveOffset(message.offset);\n      } catch (error) {\n        Logger.getInstance().error('Error in callback function', error);\n        resolveOffset(message.offset);\n      }\n    }\n  };\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAIA,oBAAuB;AACvB,sCAAuC;AAGhC,MAAM,mCAAmC,uDAAuB;AAAA,EAC9D,YACL,gBACiB,kBAGA,iBAEF,MAAM,MACrB;AACA,UAAM,cAAc;AAPH;AAGA;AAOnB,SAAO,OAAO,YAA2B;AACvC,YAAM,KAAK,SAAS,QAAQ,EAAE,MAAM,CAAC,MAAM;AACzC,6BAAO,YAAY,EAAE;AAAA,UACnB,wCAAwC,EAAE,OAAO;AAAA,QACnD;AACA,cAAM,IAAI,MAAM,wCAAwC,EAAE,OAAO,EAAE;AAAA,MACrE,CAAC;AAED,YAAM,SAAS;AAAA,QACb,GAAI,MAAM,KAAK,eAAe;AAAA,QAC9B,GAAG,KAAK,iBAAiB;AAAA,MAC3B;AAEA,YAAM,QAAQ,IAAI;AAAA,QAChB,GAAG,OAAO,IAAI,OAAO,MAAM;AACzB,gBAAM,KAAK,SAAS,UAAU,EAAE,OAAO,EAAE,CAAC;AAAA,QAC5C,CAAC;AAAA,MACH,CAAC;AAED,UAAI,KAAK,eAAe,MAAM,qBAAqB;AACjD,6BAAO,YAAY,EAAE;AAAA,UACnB;AAAA,QACF;AAAA,MACF;AAEA,YAAM,KAAK,SAAS,IAAI;AAAA,QACtB,gCACE,KAAK,eAAe,MAAM,kCAAkC;AAAA,QAC9D,sBAAsB;AAAA,QACtB,WAAW,KAAK;AAAA,MAClB,CAAC;AAAA,IACH;AAEA,SAAQ,eAAe,OAAO;AAAA,MAC5B;AAAA,MACA;AAAA,IACF,MAA+C;AAC7C,YAAM,WAAW,MAAM,SAAS;AAAA,QAAI,CAAC,YACnC,KAAK,MAAM,QAAQ,OAAO,SAAS,KAAK,EAAE;AAAA,MAC5C;AACA,2BAAO,YAAY,EAAE;AAAA,QACnB;AAAA,QACA,SAAS;AAAA,QACT,MAAM;AAAA,MACR;AAEA,UAAI,KAAK,eAAe,QAAQ,GAAG;AACjC,YAAI;AACF,gBAAM,KAAK,iBAAiB,QAAQ;AACpC,gBAAM,EAAE,OAAO,IAAI,MAAM,SAAS,MAAM,SAAS,SAAS,CAAC;AAC3D,wBAAc,MAAM;AAAA,QACtB,SAAS,OAAO;AACd,+BAAO,YAAY,EAAE;AAAA,YACnB;AAAA,YACA;AAAA,UACF;AACA,gBAAM,KAAK,qBAAqB,MAAM,UAAU,aAAa;AAAA,QAC/D;AAAA,MACF,OAAO;AACL,6BAAO,YAAY,EAAE;AAAA,UACnB;AAAA,QACF;AACA,cAAM,KAAK,qBAAqB,MAAM,UAAU,aAAa;AAAA,MAC/D;AAAA,IACF;AAEA,SAAQ,uBAAuB,OAC7B,UACA,kBACG;AAEH,iBAAW,WAAW,UAAU;AAC9B,YAAI;AACF,gBAAM,gBAAgB,KAAK,MAAM,QAAQ,OAAO,SAAS,KAAK,IAAI;AAElE,gBAAM,KAAK,iBAAiB,CAAC,aAAa,CAAC;AAC3C,wBAAc,QAAQ,MAAM;AAAA,QAC9B,SAAS,OAAO;AACd,+BAAO,YAAY,EAAE,MAAM,8BAA8B,KAAK;AAC9D,wBAAc,QAAQ,MAAM;AAAA,QAC9B;AAAA,MACF;AAAA,IACF;AAAA,EApFA;AAqFF;",
  "names": []
}
